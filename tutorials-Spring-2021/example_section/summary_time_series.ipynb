{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Time Series and Neural Network\n",
    "**Model type:** \n",
    "\n",
    "The model type is Neural Network (NN) \\nData: I only use data from prediction_list_poi, joined by weekly_patterns on the poi_id, then I select the poi_id, week_number, and visits_concentration features, with the target of raw_visit_counts\n",
    "\n",
    "**Variable transformation/feature extraction:** \n",
    "\n",
    "I changed the poi_id to be categorical data, then I use the simple method poi_id.cat.codes to change the data to be numerical.\\nFunctions: I use the function to save the preprocessed data in .npz file format since I got some difficulty with the usual data type transformation,  then I write a function to compile the model, then I predict the model using \n",
    "\n",
    "**Tensorflow, Estimation/validation technique:** \n",
    "\n",
    "At the beginning of the round, I analyze the data provided and list some ways to predict the data, I go for the simplest without too much to consider, I only use poi_id for the location pointer cause roughly the position and the city is a bit complicated to model and need to be looked into further later, and I use visits_concentration to maybe add some variable to the model, which I thought could be affecting quite much, but there is still so much to explore for this dataset.\n",
    "\n",
    "For the strengths and weaknesses of the model, to be honest, this model is no good at all by now, cause it is only a simple neural network model with some basic features from the first table, this model has yet to model the time series and predict well enough to provide any result, but with some tinkering, the neural network could be a great tool to consider, maybe using RNN or something, in addition, will be good enough, the nearest improvement I'm planning is to make n-fold validation, then exploring another variable that could be used to make the prediction better (CGB, executive_orders, covid_cases, and deaths), maybe disaggregating per city then maybe exploring ensemble learning in the future."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}