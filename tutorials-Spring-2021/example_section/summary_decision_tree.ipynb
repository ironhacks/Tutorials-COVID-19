{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Decision Tree and Random Forest\n",
    "This model is building a multi variate time series for each location. It uses the statsmodel python package for this. I used both the weekly_patterns and the cbg_social_distancing tables, merged on the week_number and cbg ids. I used the features: \n",
    "'raw_visit_counts', 'visits_concentration',  'distance_from_home', 'median_dwell', 'device_count_week', 'completely_home_device_count_per_week', 'median_home_dwell_time_per_week', 'median_non_home_dwell_time_per_week'. \n",
    "\n",
    "There was some issue with constants, so I set the model trend to be non constant to account for this issue. Each poi got its own timer sereries, trained only on the its data, resulting in 1804 models to be used for prediction. I just used the VAR model class, which allow for me to fit and predict the time series. I did some validation on the model, holding out the last 20% of observation of each poi location and seeing how well the time series was able to predict it. I got an average MSEP of about 20 from these validations run, varying greatly from the model (some were very good and some were extremely poor). I think this is better than the random forest model I made and it is much better than the boosted gradient tree that I made. I'm really new to time series so I have really found out a way to improve it yet, but I'm looking into it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}