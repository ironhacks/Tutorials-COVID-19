{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IronHacks Submission Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "---\n",
    "\n",
    "Write a brief summary about goal of this notebook and provide some insight to the reader about how read through your document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%logstop\n",
    "%logstart -t -r -q ipython_command_log.py global\n",
    "\n",
    "#- IRONHACKS RESEARCH TRACKING CODE\n",
    "#----------------------------------\n",
    "# The following code is used to help our research team understand how you \n",
    "# our notebook environment. We do not collect any personal information with\n",
    "# the following code, it is used to measure when and how often you work on\n",
    "# your submission files.\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import IPython.core.history as history\n",
    "\n",
    "ha = history.HistoryAccessor()\n",
    "ha_tail = ha.get_tail(1)\n",
    "ha_cmd = next(ha_tail)\n",
    "session_id = str(ha_cmd[0])\n",
    "command_id = str(ha_cmd[1])\n",
    "timestamp = datetime.utcnow().isoformat()\n",
    "history_line = ','.join([session_id, command_id, timestamp]) + '\\n'\n",
    "logfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\n",
    "logfile.write(history_line)\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#- INSTALL ADDITIONAL LIBRARIES IF REQUIRED\n",
    "#------------------------------------------\n",
    "# This is normally not required. The hub environment comes preinstaled with \n",
    "# many packages that you can already use without setup. In case there is some\n",
    "# other library you would like to use that isn't on the list you run this command\n",
    "# once to install them.  If it is already installed this command has no effect.\n",
    "!python3 -m pip install google.cloud\n",
    "!python3 -m pip install numpy\n",
    "!python3 -m pip install pyarrow\n",
    "!python3 -m pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#- IMPORT THE LIBRARIES YOU WILL USE\n",
    "#------------------------------------------\n",
    "# You only need to import packages one time per notebook session. To keep your\n",
    "# notebook clean and organized you can handle all imports at the top of your file.\n",
    "# The following are included for example purposed, feel free to modify or delete \n",
    "# anything in this section.\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics\n",
    "magics.context.use_bqstorage_api = True\n",
    "import pyarrow\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True, linewidth=200, edgeitems=100)\n",
    "\n",
    "# Pipeline and column transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "# Data transformers\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# Data splitter and model evaluator\n",
    "from sklearn.model_selection import train_test_split, validation_curve, learning_curve, GridSearchCV\n",
    "\n",
    "# Learning models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "#from xgboost import XGBClassifier, XGBRegressor  # Need to install\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE THE BIGQUERY SETTINGS\n",
    "\n",
    "BIGQUERY_PROJECT = 'ironhacks-covid19-data'\n",
    "BIGQUERY_KEYPATH = 'service-account.json'\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = BIGQUERY_KEYPATH\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- DEFINE YOUR CLASSES AND FUNCTIONS \n",
    "#-----------------------------------\n",
    "# This is not required, but is helpful in keeping your notebook organized. \n",
    "# You can use the following cell or several cells to define your functions\n",
    "# and classes to keep them separate from your analysis or results code.\n",
    "# In general it useful to define your methods in a separate cell from where\n",
    "# it is run.\n",
    "\n",
    "def example_function():\n",
    "    print('Hello World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to get the data I need from the big query\n",
    "\n",
    "def get_data():\n",
    "    query = \"\"\"\n",
    "    SELECT poi_id, top_category, week_number, raw_visit_counts, postal_code\n",
    "    FROM ironhacks_covid19_competition.weekly_patterns\n",
    "    \"\"\"\n",
    "    query_job = bigquery_client.query(query)\n",
    "    wp = query_job.to_dataframe()\n",
    "\n",
    "    query = \"\"\"\n",
    "    SELECT week_number, cases\n",
    "    FROM ironhacks_covid19_competition.covid19_cases\n",
    "    \"\"\"\n",
    "    query_job = bigquery_client.query(query)\n",
    "    covid = query_job.to_dataframe()\n",
    "    return wp, covid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shifting the covid_cases up one and two weeks to decrease the delay in collecting data and people's reaction towards the coivd cases\n",
    "\n",
    "def add_covid_cases(covid, wp):\n",
    "    nc = covid.copy()\n",
    "    nc['cases_shift1'] = nc['cases'].shift(1)\n",
    "    nc['cases_shift2'] = nc['cases'].shift(2)\n",
    "    del nc['cases']\n",
    "    nc = nc.fillna(7)\n",
    "    new = wp.merge(nc, on = 'week_number')\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the format of the table to having all the categories, poi_id, and postal_code as column headders\n",
    "# The fillers will be containing 0 or 1 depending on the values in week_number and raw_visit_counts\n",
    "\n",
    "def change_format(new):\n",
    "    dummy = pd.get_dummies(new['top_category'])\n",
    "    table = new.join(dummy)\n",
    "    dummy = pd.get_dummies(new['poi_id'])\n",
    "    table = table.join(dummy)\n",
    "    dummy = pd.get_dummies(new['postal_code'])\n",
    "    table = table.join(dummy)\n",
    "    del table['top_category']\n",
    "    del table['poi_id']\n",
    "    del table['postal_code']\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm making my predictinon table which contains all the known informations for week 44 except for raw_visit_counts\n",
    "\n",
    "def prediction_data(new):\n",
    "    filt_wp = new[new['week_number'] == 43]\n",
    "    dummy = pd.get_dummies(filt_wp['top_category'])\n",
    "    table2 = filt_wp.join(dummy)\n",
    "    dummy = pd.get_dummies(filt_wp['poi_id'])\n",
    "    table2 = table2.join(dummy)\n",
    "    dummy = pd.get_dummies(filt_wp['postal_code'])\n",
    "    table2 = table2.join(dummy)\n",
    "    del table2['top_category']\n",
    "    del table2['raw_visit_counts']\n",
    "    del table2['postal_code']\n",
    "\n",
    "    table2['week_number'] = table2['week_number'].replace(43, 44)\n",
    "    table2['cases_shift1'] = table2['cases_shift1'].replace(25872, 29641)\n",
    "    table2['cases_shift2'] = table2['cases_shift2'].replace(23218, 25872)\n",
    "    return table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a decision tree model based on the table we've given to it\n",
    "# I set raw_visit_counts as the Y value and everything else is X\n",
    "# Also splited the data randomly into 80% for training set and 20% for testing\n",
    "# Prints out the training score and testing score\n",
    "\n",
    "\n",
    "def decision_tree(table):\n",
    "    df = table\n",
    "    X = df.drop(['raw_visit_counts'], axis=1)\n",
    "    y = df['raw_visit_counts']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=0)\n",
    "\n",
    "    decision_tree_model = DecisionTreeRegressor(random_state=0)\n",
    "    decision_tree_model.fit(X_train, y_train)\n",
    "    print('Decision Tree Training score:', decision_tree_model.score(X_train,y_train))\n",
    "    print('Decision Tree Test score:    ', decision_tree_model.score(X_test,y_test),'\\n')\n",
    "    return decision_tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicts the week 44's raw_visit_counts given the trained model and the week 44 known data\n",
    "\n",
    "def presict_week_44(table2, decision_tree_model):\n",
    "    X_predict = table2\n",
    "    poi_id = table2['poi_id']\n",
    "    del X_predict['poi_id']\n",
    "    raw_visit_counts = decision_tree_model.predict(X_predict)\n",
    "\n",
    "\n",
    "    d = pd.DataFrame(columns = ['poi_id', 'raw_visit_counts'])\n",
    "    d['poi_id'] = poi_id\n",
    "    d['raw_visit_counts'] = raw_visit_counts\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/client.py:441: UserWarning: Cannot create BigQuery Storage client, the dependency google-cloud-bigquery-storage is not installed.\n",
      "  \"Cannot create BigQuery Storage client, the dependency \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training score: 1.0\n",
      "Decision Tree Test score:     0.9581896310451774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the functions and store the predicted result in the variable called result\n",
    "\n",
    "example_function()\n",
    "wp,covid = get_data()\n",
    "combined = add_covid_cases(covid, wp)\n",
    "table = change_format(combined)\n",
    "table2 = prediction_data(combined)\n",
    "decision_tree_model = decision_tree(table)\n",
    "result = presict_week_44(table2, decision_tree_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "---\n",
    "\n",
    "This section may not be necessary for you individual notebook, but if you've created nice charts or tables you can present them together with some explanation in section. In addition if you have any comments or thoughts about what you would like to do or items that are still in progress you can summarize them at the bottom of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This can also be a good place for you to cleanup any input/output and export your results to a file.\n",
    "# Storing the result into the csv file\n",
    "result.to_csv('submission_prediction_output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
