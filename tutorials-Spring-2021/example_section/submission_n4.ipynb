{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "submission_prediction_output.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "source": [
        "## Background Information\n",
        "---\n",
        "\n",
        "This information has been deleted by the IronHacks Team"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWtsu3uXr_hu"
      },
      "source": [
        "## Setup\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4BgIw7xr_hw"
      },
      "source": [
        "\n",
        "%logstop\n",
        "%logstart -t -r -q ipython_command_log.py global\n",
        "\n",
        "#- IRONHACKS RESEARCH TRACKING CODE\n",
        "#----------------------------------\n",
        "# The following code is used to help our research team understand how you \n",
        "# our notebook environment. We do not collect any personal information with\n",
        "# the following code, it is used to measure when and how often you work on\n",
        "# your submission files.\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "import IPython.core.history as history\n",
        "\n",
        "ha = history.HistoryAccessor()\n",
        "ha_tail = ha.get_tail(1)\n",
        "ha_cmd = next(ha_tail)\n",
        "session_id = str(ha_cmd[0])\n",
        "command_id = str(ha_cmd[1])\n",
        "timestamp = datetime.utcnow().isoformat()\n",
        "history_line = ','.join([session_id, command_id, timestamp]) + '\\n'\n",
        "logfile = open(os.environ['HOME']+'/ipython_session_log.csv', 'a')\n",
        "logfile.write(history_line)\n",
        "logfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzkWCU9or_hx"
      },
      "source": [
        "\n",
        "!python3 -m pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij3kj4s4r_hx"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2I0kdblr_hx"
      },
      "source": [
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm \n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "from google.cloud.bigquery import magics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKEIsL2dr_hy"
      },
      "source": [
        "# CONFIGURE THE BIGQUERY SETTINGS\n",
        "\n",
        "BIGQUERY_PROJECT = 'ironhacks-covid19-data'\n",
        "BIGQUERY_KEYPATH = 'service-account.json'\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = BIGQUERY_KEYPATH\n",
        "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ianAMs7tr_hy"
      },
      "source": [
        "def printexcel(result, filename):\n",
        "    frame = pd.DataFrame(list(result.items()), columns=['poi_id','raw_visit_counts'])\n",
        "    frame['raw_visit_counts'] =  frame['raw_visit_counts'].apply(lambda x: str(x).replace('[','').replace(']',''))\n",
        "    frame['raw_visit_counts'] = frame['raw_visit_counts'].astype(float)\n",
        "    frame.to_csv(filename, index=False)\n",
        "def printexcellessprocessing(frame, filename):\n",
        "    frame['raw_visit_counts'] = frame['raw_visit_counts'].apply(lambda x: str(x).replace('[','').replace(']',''))\n",
        "    frame['raw_visit_counts'] = frame['raw_visit_counts'].astype(float)\n",
        "    frame.to_csv(filename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0Cb2E0Ur_hz"
      },
      "source": [
        "## Query Data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNKByOTur_hz"
      },
      "source": [
        "\n",
        "#Linear regression all the data\n",
        "#right join means only poi_ids that we need\n",
        "query1 = \"\"\"\n",
        "SELECT prediction.poi_id, weekly.location_name, weekly.raw_visit_counts, weekly.week_number\n",
        "FROM `ironhacks_covid19_competition`.`weekly_patterns` as weekly\n",
        "right join `ironhacks_covid19_competition`.`prediction_list_poi` as prediction\n",
        "on weekly.poi_id = prediction.poi_id\n",
        "\"\"\"\n",
        "\n",
        "query_job1 = bigquery_client.query(query1)\n",
        "query_result_all = query_job1.to_dataframe()\n",
        "print(query_result_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulRLeOzxr_hz"
      },
      "source": [
        "\n",
        "#Linear regression data from week 34 onward looks much more apetizing\n",
        "#right join means only poi_ids that we need\n",
        "query2 = \"\"\"\n",
        "SELECT prediction.poi_id, weekly.raw_visit_counts, weekly.week_number\n",
        "FROM `ironhacks_covid19_competition`.`weekly_patterns` as weekly\n",
        "right join `ironhacks_covid19_competition`.`prediction_list_poi` as prediction\n",
        "on weekly.poi_id = prediction.poi_id\n",
        "where week_number >= 34\n",
        "\"\"\"\n",
        "\n",
        "query_job2 = bigquery_client.query(query2)\n",
        "query_result_34 = query_job2.to_dataframe()\n",
        "print(query_result_34.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLoKPd1gr_h0"
      },
      "source": [
        "\n",
        "query3 = \"\"\"\n",
        "SELECT prediction.poi_id, weekly.location_name, weekly.week_number, weekly.visits_concentration, weekly.raw_visit_counts, weekly.distance_from_home, weekly.median_dwell\n",
        "FROM `ironhacks_covid19_competition`.`weekly_patterns` as weekly\n",
        "right join `ironhacks_covid19_competition`.`prediction_list_poi` as prediction\n",
        "on weekly.poi_id = prediction.poi_id\n",
        "\"\"\"\n",
        "\n",
        "query_job3 = bigquery_client.query(query3)\n",
        "query_result_weekly = query_job3.to_dataframe()\n",
        "print(query_result_weekly.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVWuM40sr_h0"
      },
      "source": [
        "\n",
        "query4 = \"\"\"\n",
        "SELECT week_number, cases, deaths\n",
        "FROM `ironhacks_covid19_competition`.`covid19_cases`\n",
        "where county = 'Tippecanoe'\n",
        "\"\"\"\n",
        "\n",
        "query_job4 = bigquery_client.query(query4)\n",
        "query_result_covid = query_job4.to_dataframe()\n",
        "print(query_result_covid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzWW8E-ar_h1"
      },
      "source": [
        "## Graphs just to visualize some data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3RLQiEsr_h1"
      },
      "source": [
        "#Plotted the data across all locations to see the jist of it\n",
        "data_to_graph = pd.DataFrame(query_result_all, columns=['poi_id','raw_visit_counts', 'week_number'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-PRnXR0r_h1"
      },
      "source": [
        "data_to_graph.plot(x ='week_number', y='raw_visit_counts', kind = 'line')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHpFwfhlr_h2"
      },
      "source": [
        "#I am just curious what the two locations that spiked are\n",
        "query_result_alltemp = query_result_all[query_result_all['raw_visit_counts'] > 6000]\n",
        "print(query_result_alltemp['location_name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktFo11Lnr_h2"
      },
      "source": [
        "query_result_covid.plot(x ='week_number', y='cases', kind = 'line')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLBAf9MOr_h2"
      },
      "source": [
        "query_result_covid.plot(x ='week_number', y='deaths', kind = 'line')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYYroOKsr_h3"
      },
      "source": [
        "#I did some research and in week 33 they reclassified covid deaths to need an official test \n",
        "#so 98 deaths went to 13 deaths according to IN.gov. If you extend the rate of of probable deaths \n",
        "#(7.5 times (=98/13) as many added after the change ) we \n",
        "#should have almost 350 in tippecanoe county, instead of the 42 listed on the official government webpage. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJWFHNxnr_h3"
      },
      "source": [
        "## Trying to see if there is any colinearity among some likely suspects\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAQW3Ijur_h3"
      },
      "source": [
        "#hmm bummer nothing to work with here or else I would have nabbed some coefficients and went to work for multiple regression\n",
        "#or some machine learning algo\n",
        "corr = query_result_weekly.corr()\n",
        "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True), square=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOHCRkUgr_h4"
      },
      "source": [
        "## Model 1, Linear Regression\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpAvwavKr_h4"
      },
      "source": [
        "#linear regression just to see how bad it is, looks kinda linear bar Purdue??\n",
        "def regression(data, yvar, xvars):\n",
        "    result = sm.OLS(data[yvar], data[xvars]).fit()\n",
        "    return result.predict(44)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLb-vmUBr_h4"
      },
      "source": [
        "#r squared value average for all the models, not bad tbh\n",
        "def regressionsquare(data, yvar, xvars):\n",
        "    result = sm.OLS(data[yvar], data[xvars]).fit()\n",
        "    return result.rsquared\n",
        "result = query_result_all.groupby('poi_id').apply(regressionsquare, 'raw_visit_counts', 'week_number')\n",
        "print(result.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpoRLaCdr_h5"
      },
      "source": [
        "result_dict1 = query_result_all.groupby('poi_id').apply(regression, 'raw_visit_counts', 'week_number').to_dict()\n",
        "printexcel(result_dict1, 'model1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5Gnfu_7r_h6"
      },
      "source": [
        "## Model 2, Linear Regression after week 33\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjQkMxwRr_h6"
      },
      "source": [
        "#r squared value average for all the models past week 33, jeesh pretty decent might end up going with this guy for accuracy\n",
        "def regressionsquare(data, yvar, xvars):\n",
        "    result = sm.OLS(data[yvar], data[xvars]).fit()\n",
        "    return result.rsquared\n",
        "result = query_result_34.groupby('poi_id').apply(regressionsquare, 'raw_visit_counts', 'week_number')\n",
        "print(result.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ6kO1cjr_h6"
      },
      "source": [
        "result_dict2 = query_result_34.groupby('poi_id').apply(regression, 'raw_visit_counts', 'week_number').to_dict()\n",
        "printexcel(result_dict2, 'model2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUgJlPuar_h6"
      },
      "source": [
        "## Model 3, try to find better models for bad guys\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCh3w97Br_h7"
      },
      "source": [
        "#my logic is these might not be linear or need some parameter adjusting or forced intercept\n",
        "#this module shows how many are not happy with the R2 value\n",
        "#'result' variable is from either model 1 or model 2\n",
        "resultdict = result.to_dict()\n",
        "badmodels = dict()\n",
        "verybadmodels = dict()\n",
        "veryverybadmodels = dict()\n",
        "sum = 0\n",
        "for (key, value) in resultdict.items():\n",
        "    if value < .8: #and value > .7: #decided I wanted to look at all of these instead, used to be .9, now .8\n",
        "        badmodels[key] = value\n",
        "    if value < .7 and value > .5:\n",
        "        verybadmodels[key] = value\n",
        "    if value < .5:\n",
        "        veryverybadmodels[key] = value\n",
        "    sum = sum + value\n",
        "print(len(badmodels))\n",
        "print(len(verybadmodels))\n",
        "print(len(veryverybadmodels))\n",
        "print(sum/len(resultdict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJWG65zvr_h7"
      },
      "source": [
        "# Model 3a, exponential models\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-zqrTR2r_h7"
      },
      "source": [
        "#I revisted this with query_result_34, which chops off older data before week 34\n",
        "#'result_dict2' variable is from model 2, change to 'result_dict1' if model 1 is used \n",
        "frame = pd.DataFrame(list(result_dict2.items()), columns=['poi_id','raw_visit_counts'])\n",
        "pois = list(badmodels)\n",
        "#----------------------------------------------\n",
        "#Iteration 1, query_result_all\n",
        "#Trying for exponential fit, only found 1 poi_id above .9 fit.. (.98 4 data points) maybe in the future \n",
        "#if I chop off some data it will fit more, ignoring the 1 model for now\n",
        "#I need a cutoff or some type of dampening for values so the predictions are not too high\n",
        "#I graphed (veryverybad) guys and they look very much e^(-x)=y or e^(x)=y\n",
        "#----------------------------------------------\n",
        "#Iteration 2, query_result_34\n",
        "# NOW WE'RE IN BUSINESS\n",
        "# these are decent results for a varity of poi's. The estimate values are very solid by visual inspection\n",
        "# After deciding these are trustworthy I am lowering the bar to .8\n",
        "#----------------------------------------------\n",
        "count =0\n",
        "for i in range(len(pois)):\n",
        "    #data that did not model well\n",
        "    test = query_result_34.loc[query_result_34['poi_id'] == pois[i]]\n",
        "    \n",
        "    Y = test['raw_visit_counts']\n",
        "    X = test['week_number']\n",
        "    Y = np.stack(Y.values).reshape(-1,1)\n",
        "    X = np.stack(X.values).reshape(-1,1)\n",
        "\n",
        "    transformer = FunctionTransformer(np.log, validate=True)\n",
        "    Y1 = transformer.fit_transform(Y) \n",
        "    regressor = LinearRegression()\n",
        "    results = regressor.fit(X, Y1) \n",
        "    r2 = regressor.score(X, Y1)\n",
        "    yfit = results.predict([[44]])\n",
        "    predict44 = np.exp(yfit)\n",
        "    if r2 > .8:\n",
        "        #print(r2)\n",
        "        #print(resultdict[pois[i]])\n",
        "        #print(predict44)\n",
        "        #print('\\n')\n",
        "        #test.plot(x ='week_number', y='raw_visit_counts', kind = 'scatter')\n",
        "        #plt.show()\n",
        "        \n",
        "        resultdict[pois[i]] = r2 #update r2 value\n",
        "        #set the predicted value of that model here\n",
        "        frame.loc[frame['poi_id'] == pois[i], ['raw_visit_counts']] = predict44\n",
        "        count =count+1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziCLWdaUr_h7"
      },
      "source": [
        "#don't forge to run this in between. I decided I like exponential fit so if it meets the criteria, I want to prefer it.\n",
        "#now we have a new list of bad models!\n",
        "badmodels = dict()\n",
        "verybadmodels = dict()\n",
        "veryverybadmodels = dict()\n",
        "count = 0\n",
        "for (key, value) in resultdict.items():\n",
        "    if value < .8:\n",
        "        badmodels[key] = value\n",
        "    if value < .7 and value > .5:\n",
        "        verybadmodels[key] = value\n",
        "    if value < .5:\n",
        "        veryverybadmodels[key] = value\n",
        "    count=count+value\n",
        "print(len(badmodels))\n",
        "print(len(verybadmodels))\n",
        "print(len(veryverybadmodels))\n",
        "print(count/len(resultdict))\n",
        "#there is a slight improvement in the mean R^2 value of all the models, only slight- we only fixed 25"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNZJu94ir_h8"
      },
      "source": [
        "## Model 3b, polynomial models (d=2,3)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAAea4Prr_h8"
      },
      "source": [
        "#I revisted this with query_result_34, which chops off older data before week 34\n",
        "pois = list(badmodels)\n",
        "#----------------------------------------------\n",
        "#Iteration 1, query_result_all\n",
        "#----------------------------------------------\n",
        "#trying polynomial fit degree 2, only found a few results with poor estimations, not surprising,\n",
        "#seems like a silly model given the context of the problem\n",
        "#trying polynomial fit degree 3\n",
        "#DANGER zone? 4 point data sets R2=1... Perfect?lol But obviously wayyy overfit- Not sure how to handle that.\n",
        "#Update on DANGER zone: This creates horrible predictions, not at all what I want\n",
        "#----------------------------------------------\n",
        "#Iteration 2, query_result_34\n",
        "#----------------------------------------------\n",
        "#This is better but I am worried about overfitting, clearly based on the graphs some of them fit well\n",
        "#but the predictions are inconsistent and I'm worried it would throw my error off.\n",
        "#I am going to look at fits of .95 or more only, exclude those with only 4 points\n",
        "#----------------------------------------------\n",
        "#Iteration 3, query_result_34, after I applied exponential fit to 25 models\n",
        "#----------------------------------------------\n",
        "# Not looking too good, only 2 models and 1 of them gives a poor estimation. ugh. I am going to apply\n",
        "#this to the 1 though because its a sexy X^3 fit\n",
        "#----------------------------------------------\n",
        "count = 0\n",
        "for i in range(len(pois)):\n",
        "    #data that did not model well\n",
        "    test = query_result_34.loc[query_result_34['poi_id'] == pois[i]]\n",
        "    \n",
        "    Y = test['raw_visit_counts']\n",
        "    X = test['week_number']\n",
        "    Y = np.stack(Y.values).reshape(-1,1)\n",
        "    X = np.stack(X.values).reshape(-1,1)\n",
        "    \n",
        "    poly = PolynomialFeatures(degree=3)\n",
        "    X1 = poly.fit_transform(X)\n",
        "    Y1 = poly.fit_transform([[44]])\n",
        "\n",
        "    clf = linear_model.LinearRegression()\n",
        "    clf.fit(X1, Y)\n",
        "    predict44 = clf.predict(Y1)\n",
        "    r2 = clf.score(X1, Y)\n",
        "    if r2 > .95 and r2 != 1 and pois[i] != '30d6715f-78a3-4ee7-b4ca-fea7706ff9e8': #This guy was a bad fit\n",
        "        #print(r2)\n",
        "        #print(resultdict[pois[i]])\n",
        "        #print(predict44)\n",
        "        #print('\\n')\n",
        "        #test.plot(x ='week_number', y='raw_visit_counts', kind = 'scatter')\n",
        "        #plt.show()\n",
        "        resultdict[pois[i]] = r2 #update r2 value\n",
        "        #set the predicted value of that model here\n",
        "        frame.loc[frame['poi_id'] == pois[i], ['raw_visit_counts']] = predict44\n",
        "        count = count + 1\n",
        "print(count)\n",
        "#'1' is the loneliest number, but the sexiest fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTNQqUM1r_h8"
      },
      "source": [
        "#updated resultdict results\n",
        "badmodels = dict()\n",
        "verybadmodels = dict()\n",
        "veryverybadmodels = dict()\n",
        "count = 0\n",
        "for (key, value) in resultdict.items():\n",
        "    if value < .8: #and value > .7: #decided I wanted to look at all of these instead, used to be .9, now .8\n",
        "        badmodels[key] = value\n",
        "    if value < .7 and value > .5:\n",
        "        verybadmodels[key] = value\n",
        "    if value < .5:\n",
        "        veryverybadmodels[key] = value\n",
        "    count=count+value\n",
        "print(len(badmodels))\n",
        "print(len(verybadmodels))\n",
        "print(len(veryverybadmodels))\n",
        "print(count/len(resultdict))\n",
        "#only fixed 1 additional model, so really no change"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bQRPxNKr_h9"
      },
      "source": [
        "printexcellessprocessing(frame, 'submission_prediction_output.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YPSQcSnr_h9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}