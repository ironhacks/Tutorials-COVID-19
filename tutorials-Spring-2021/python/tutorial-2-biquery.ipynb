{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #2: How to query data from BigQuery in a Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Welcome to part II of our tutorials designed for participants in the IronHacks. In this second notebook (part II), we will show you how you can access our training data stored in BigQuery using a key stored in your user profile.**\n",
    "\n",
    "**Before you get started**: This tutorial will not take more than 10 minutes and you should have the basic skill sets to work with the datasets thereafter. \n",
    "\n",
    "**Our goal**: Help you get started with the Python BigQuery Library, Python Pandas Library and Python Numpy Library in order to access a first temporal dataset stored in BigQuery! So if you have never used these libraries before this tutorial is critical for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery - What's that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigQuery is Google's flagship data warehousing system: \"Serverless, highly scalable, and cost-effective multi-cloud data warehouse designed for business agility\". It allows you to analyze large amount of data using ANSI SQL at blazing-fast speeds, with zero operational overhead. You can find out more it at https://cloud.google.com/bigquery\n",
    "\n",
    "**Why do we use BigQuery?** In the COVID-19 Data Science Challenges you will use BIG DATA from our data providers SafeGraph, the Management Performance Hub (MPH), and other partners (Department of Workforce Development). The first hack Summer 2020, will use preprocessed data so you will not need to use all the functionalities of BIG QUERY as we have sampled down more than 50 datasets with more than 1 TB and millions of raws into a small sets of cleaned tables without missing entries and clear identifiers. However, using BigQuery will still be very helpful as you can see for exploring data without having to use them in memory etc. It will also set you up for the future of data science since BigQuery is replacing other BIG DATA services (e.g. Spark).\n",
    "\n",
    "**How do we give you access to BigQuery?** In Big Query data are stored in projects. Inside a project there are multiple datasets. Each dataset can contain multiple tables. In this hack we give you access to a project called: `ironhacks-covid19-data`. In this project there are two datasets:`ironhacks-covid19-data:ironhacks_covid19_training` and `ironhacks-covid19-data:ironhacks_covid19_competition`. During the training period you will only find data in the first dataset. In this first tutorial we only use one first relatively simply structured table stored in this dataset. It is called `covid19_tests_cases_deaths_IN`\n",
    "\n",
    "**Keep in mind**: In this tutorial you will learn how to get access to the ironhacks-covid19-data and the datset ironhacks-covid19-data:ironhacks_covid19_training stored inside this project.\n",
    "\n",
    "**What's BigQuery**: Google Cloud Big Query package allows you to query data stored in BigQuery You can find the official documentation [here](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "\n",
    "**What's Pandas** In computer programming, pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series\n",
    "\n",
    "**What's Numpy** NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I: Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "!python3 -m pip install google.cloud\n",
    "!python3 -m pip install pandas\n",
    "!python3 -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section II: Authorizing your BigQuery Access\n",
    "\n",
    "- Finding the key in user profile (screenshot to be added - see notebook part I) \n",
    "- Adding the key using the BigRquery functionality\n",
    "- Verificing that token is valid\n",
    "- Getting the project(s) names that the token is authorized for establishing the database connection\n",
    "- Listing the tables in the project\n",
    "\n",
    "__So the next step now is to find the keys__: \n",
    "\n",
    "1. Go to your user profile\n",
    "1. click on Download your hack dataset training key \n",
    "1. Upload it to your Juptyer lab environment\n",
    "\n",
    "After this, you will set the `GOOGLE_APPLICATION_CREDENTIALS` to point to the path of your key as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE THE BIGQUERY SETTINGS\n",
    "\n",
    "BIGQUERY_PROJECT = 'ironhacks-covid19-data'\n",
    "BIGQUERY_KEYPATH = '/home/jovyan/key.json'\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = BIGQUERY_KEYPATH\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks_covid19_training.ironhacks_covid19_training.covid19_cases`\n",
    "\"\"\"\n",
    "\n",
    "# QUERY THE DATA ONCE\n",
    "query_job = bigquery_client.query(query)\n",
    "in_test_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THEN WORK BELOW TO DO SOMETHING THE RESULTS\n",
    "print(\"Columns:\")\n",
    "print('\\n'.join(in_test_data.columns))\n",
    "print(\"\\nResults:\")\n",
    "print(in_test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section III: Exploring the table and loading the table\n",
    "\n",
    "- What is the schema\n",
    "- How many rows\n",
    "- How big is the table\n",
    "- Loading the table as dataframe and describing the table\n",
    "\n",
    "Here, we wil explore how many rows the table is having. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM `ironhacks_covid19_training.ironhacks_covid19_training.covid19_cases`\n",
    "\"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query)\n",
    "in_case_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_case_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section IV: Querying the table\n",
    "\n",
    "So what we will do:\n",
    "\n",
    "- Subsetting the table for DATE,COVID_TEST, COVID_COUNT and filtering for period 2020-01-01 to 2020-02-25\n",
    "- Calculating the mean cases for the period with numpy and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT DATE, COVID_TEST\n",
    "FROM `ironhacks_covid19_training.ironhacks_covid19_training.covid19_cases`\n",
    "WHERE DATE BETWEEN '2021-01-01'AND '2021-02-025'\n",
    "ORDER BY DATE\n",
    "\"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query)\n",
    "in_test_count_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(in_test_count_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame(in_test_count_data, columns = ['COVID_TEST'])\n",
    "print(\"mean: \", df.mean()); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}