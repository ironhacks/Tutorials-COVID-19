{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #2: How to query data from BigQuery in a Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Welcome to part II of our tutorials designed for participants in the IronHacks. In this second notebook (part II), we will show you how you can access our training data stored in BigQuery using a key stored in your user profile.**\n",
    "\n",
    "**Before you get started**: This tutorial will not take more than 10 minutes and you should have the basic skill sets to work with the datasets thereafter. \n",
    "\n",
    "**Our goal**: Help you get started with the Python BigQuery Library, Python Pandas Library and Python Numpy Library in order to access a first temporal dataset stored in BigQuery! So if you have never used these libraries before this tutorial is critical for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery - What's that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BigQuery is Google's flagship data warehousing system: \"Serverless, highly scalable, and cost-effective multi-cloud data warehouse designed for business agility\". It allows you to analyze large amount of data using ANSI SQL at blazing-fast speeds, with zero operational overhead. You can find out more it at https://cloud.google.com/bigquery\n",
    "\n",
    "**Why do we use BigQuery?** In the Unemployment Data Science Challenges you will use BIG DATA from our data provider, the Department of Workforce Development (DWD). Using Big Query will be very helpful as you can explore data without having to use them in memory etc. It will also set you up for the future of data science since BigQuery is replacing other BIG DATA services (e.g. Spark).\n",
    "\n",
    "**How do we give you access to BigQuery?** In Big Query data are stored in projects. Inside a project there are multiple datasets. Each dataset can contain multiple tables. In this hack we give you access to a project called: `ironhacks-data`. In this project there are two datasets:`ironhacks-data:ironhacks_training` and `ironhacks-data:ironhacks_competition`. During the training period you will only find data in the first dataset. In this first tutorial we only use one first relatively simply structured table stored in this dataset. It is called `covid19_cases`\n",
    "\n",
    "**Keep in mind**: In this tutorial you will learn how to get access to the ironhacks-covid19-data and the datset ironhacks-covid19-data:ironhacks_covid19_training stored inside this project.\n",
    "\n",
    "**What's BigQuery**: Google Cloud Big Query package allows you to query data stored in BigQuery You can find the official documentation [here](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "\n",
    "**What's Pandas** In computer programming, pandas is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series\n",
    "\n",
    "**What's Numpy** NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section I: Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.bigquery import magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section II: Authorizing your BigQuery Access\n",
    "\n",
    "- Open a terminal tab in your Notebook Environment\n",
    "- Copy each command and follow the instructions provided by Google\n",
    "- Setting the project(s) names that the you are authorized for to establish the database connection\n",
    "- Listing the tables in the project\n",
    "\n",
    "> Note: You will need to re-run the terminal commands each time you re-open the notebook. But this will only need to be done once per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these terminal commands when your Notebook Session begins\n",
    "!gcloud auth login\n",
    "!gcloud auth application-default set-quota-project ironhacks-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE THE BIGQUERY SETTINGS\n",
    "\n",
    "BIGQUERY_PROJECT = 'ironhacks-data'\n",
    "bigquery_client = bigquery.Client(project=BIGQUERY_PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM `ironhacks-data.ironhacks_training.covid19_cases`\n",
    "\"\"\"\n",
    "\n",
    "# QUERY THE DATA ONCE\n",
    "query_job = bigquery_client.query(query)\n",
    "covid19_cases_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "week_number\n",
      "cases\n",
      "\n",
      "Results:\n",
      "   week_number  cases\n",
      "0            1   5289\n",
      "1            2   3460\n",
      "2            3   2794\n"
     ]
    }
   ],
   "source": [
    "# THEN WORK BELOW TO DO SOMETHING THE RESULTS\n",
    "print(\"Columns:\")\n",
    "print('\\n'.join(covid19_cases_data.columns))\n",
    "print(\"\\nResults:\")\n",
    "print(covid19_cases_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section III: Exploring the table and loading the table\n",
    "\n",
    "- What is the schema\n",
    "- How many rows\n",
    "- How big is the table\n",
    "- Loading the table as dataframe and describing the table\n",
    "\n",
    "Here, we wil explore how many rows the table is having. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM `ironhacks-data.ironhacks_training.covid19_cases`\n",
    "\"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query)\n",
    "covid19_cases_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   f0_\n",
      "0   14\n"
     ]
    }
   ],
   "source": [
    "print(covid19_cases_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section IV: Querying the table\n",
    "\n",
    "So what we will do:\n",
    "\n",
    "- Subsetting the table for 'week_number' and 'cases' and filtering for week 1 to week 3\n",
    "- Calculating the mean cases for the period with numpy and pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "week_number,\n",
    "cases \n",
    "FROM `ironhacks-data.ironhacks_training.covid19_cases`\n",
    "Where week_number between 1 and 3\n",
    "order by week_number\n",
    "\"\"\"\n",
    "\n",
    "query_job = bigquery_client.query(query)\n",
    "covid19_cases_data = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   week_number  cases\n",
      "0            1   5289\n",
      "1            2   3460\n",
      "2            3   2794\n"
     ]
    }
   ],
   "source": [
    "print(covid19_cases_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  cases    3847.666667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame(covid19_cases_data, columns = ['cases'])\n",
    "print(\"mean: \", df.mean()); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "85b60a31454430fbce5bbe029920fcbdcb9e68607c9fac40f23011283ad9992b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
